import tensorflow as tf
from tensorflow import keras

from tensorflow.keras import Sequential
from tensorflow.keras.layers import Conv2D, Flatten, Dense,MaxPooling2D, Dropout

# from keras.models import Sequential
# from keras.layers import Dense,Flatten,Conv2D,MaxPooling2D, Dropout
from tensorflow.keras import layers
from keras.utils import to_categorical
import numpy as np
import matplotlib.pyplot as plt
plt.style.use('fivethirtyeight')

# Load the data
from keras.datasets import cifar10
(x_train,y_train),(x_test,y_test)=cifar10.load_data()

##############################################################

#show the image as a picture
index=0
img=plt.imshow(x_train[index])

#get the image classification
classification=['airplane','automobile','bird','cat','deer','dog','frog','horse','ship','truck']
#print the image class
print('The image class is: ',classification[y_train[index][0]])

#Convert the labels into a 10 numbers to input into the neural network
y_train_one_hot=to_categorical(y_train)
y_test_one_hot=to_categorical(y_test)

#Normilize the pixels to be values between 0 and 1
x_train=x_train/255
x_test=x_test/255

#Create the models architecture
model=Sequential()
# Add the first layer
model.add(Conv2D(32,(5,5),activation='relu',input_shape=(32,32,3)))

# Add a pooling layer
model.add(MaxPooling2D(pool_size=(2,2)))

#Add another convolution layer
model.add(Conv2D(32,(5,5),activation='relu'))

# Add another pooling layer
model.add(MaxPooling2D(pool_size=(2,2)))

# Add a flattening layer
model.add(Flatten())

# Add a layer with 1000 neurons
model.add(Dense(1000, activation='relu'))

# Add a drop out layer
model.add(Dropout(0.5))

# Add a layer with 500 neurons
model.add(Dense(500, activation='relu'))

# Add a drop out layer
model.add(Dropout(0.5))

# Add a layer with 250 neurons
model.add(Dense(250, activation='relu'))

# Add a layer with 10 neurons
model.add(Dense(10, activation='softmax'))

# Compile the model
model.compile(loss='categorical_crossentropy',
              optimizer='SGD',
              metrics=['accuracy'],
              )
# Train the model
hist=model.fit(x_train,y_train_one_hot,
               batch_size=256,
               epochs=5,
               validation_split=0.2,

              
               )

# Evaluate the model using the test dataset
model.evaluate(x_test,y_test_one_hot)[1]

#Visualize the models accuracy
plt.plot(hist.history['accuracy'])
plt.plot(hist.history['val_accuracy'])
plt.title('Model accuracy')
plt.ylabel('Accuracy')
plt.xlabel('Epoch')
plt.legend(['Train','Validation'],loc='upper left')
plt.show()

#Visualize the model loss
plt.plot(hist.history['loss'])
plt.plot(hist.history['val_loss'])
plt.title('Model loss')
plt.ylabel('Loss')
plt.xlabel('Epoch')
plt.legend(['Train','Validation'],loc='upper right')
plt.show()

# Show the image
new_image=plt.imread(r'C:\Users\Hossein\Pictures\deer.jpg')
img=plt.imshow(new_image)

# Resize the image
from skimage.transform import resize
resized_image=resize(new_image,(32,32,3))
img=plt.imshow(resized_image)

# Get the model prediction
predictions=model.predict(np.array([resized_image])) 

# Sort thepredictions from least to greatest
list_index=[0,1,2,3,4,5,6,7,8,9]
x=predictions
for i in range(10):
  for j in range(10):
    if x[0][list_index[i]] > x[0][list_index[j]]:
      temp=list_index[i]
      list_index[i]=list_index[j]
      list_index[j]=temp
# Show the sorted labels in order
print(list_index)

# Print the first 5 predictions
for i in range(5):
  print(classification[list_index[i]], ':', round(predictions[0][list_index[i]]*100,2), '%')
